AetherMind â€” A Modular, Extensible RAG Framework
AetherMind is a fully modular Retrievalâ€‘Augmented Generation (RAG) backend built from scratch.
Itâ€™s designed for clarity, extensibility, and realâ€‘world engineering practices â€” with pluggable vectorstores, interchangeable embedding backends, clean retrieval orchestration, and a memory system supporting both shortâ€‘term and longâ€‘term context.

This project demonstrates how to build a productionâ€‘grade RAG pipeline without relying on monolithic frameworks.

ğŸš€ Features
Core Pipeline
Ingestion pipeline: preprocessing, chunking, embedding, vectorstore upsert

Retriever with vector search, scoring, and optional reranking

Memory system with shortâ€‘term FIFO memory and longâ€‘term persistent memory

Embedding backends including SentenceTransformers and an OpenAIâ€‘compatible interface

Vectorstores including an inâ€‘memory Chromaâ€‘like store, Pinecone adapter, and Qdrant adapter

FastAPI server with clean routing and shared state

CI pipeline using GitHub Actions

Full test suite for embeddings, vectorstore, and retriever

ğŸ§© Architecture Overview
Ingest flow:
Preprocess â†’ Chunking â†’ Embeddings â†’ Vectorstore â†’ Longâ€‘term Memory

Query flow:
Embeddings â†’ Retriever â†’ Memory Context â†’ Response Assembly

The retriever merges vectorstore hits with both shortâ€‘term and longâ€‘term memory to produce a final context set.

ğŸ“¦ Installation
Clone the repository, install dependencies, and ensure SentenceTransformers is available.
No external API keys are required unless you choose to enable OpenAI embeddings.

ğŸƒ Running the API
Start the FastAPI server using Uvicorn.
The API root is available at localhost:8000, and interactive documentation is available at /docs.

ğŸ“¥ Ingesting Text
Send a POST request to the /ingest endpoint with text or a file path.
You can configure chunk size, overlap, and whether to persist longâ€‘term memory.

ğŸ” Querying
Send a POST request to /query with a naturalâ€‘language question.
The response includes:

Retrieved chunks

Similarity scores

Shortâ€‘term memory context

Longâ€‘term memory context

ğŸ§ª Tests
A full pytest suite validates:

Embedding backend behavior

Vectorstore operations

Retriever orchestration

ğŸ”„ CI Pipeline
GitHub Actions automatically runs tests on every push and pull request.
The workflow installs dependencies, runs pytest, and caches packages for faster builds.

ğŸ§  Project Goals
AetherMind is built to be:

Readable â€” small, focused modules

Extensible â€” pluggable components at every layer

Tested â€” reliable behavior across the pipeline

Practical â€” real embeddings, real retrieval, real memory

Ideal for:

Chatbots

Document QA

Personal knowledge bases

Research assistants

RAG experimentation

ğŸ“Œ Roadmap
Evaluation module (retrieval quality, hallucination checks)

Optional frontend (chat UI + file upload)

Vectorstore persistence layer

Reranking improvements (crossâ€‘encoder)

LLM synthesis layer (answer generation)
